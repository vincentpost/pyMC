{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LLM-Assisted Coding for Hydrology and GIS\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we'll explore how to use AI-assisted coding to perform hydrological calculations and integrate GIS data. We'll start with basic hydrological functions and progressively move to more complex operations involving GIS data processing.\n",
        "\n",
        "The code provided in the code cells was generated by ChatGPT and pasted into this notebook using the prompts provided throughout this notebook. To view the ChatGPT conversation where all the code was generated, see the link below. ChatGPT will probably not generate the code exactly the same way as I have currently in the code cells, but that is okay as long as the code returns the expected output. The prompts to use with ChatGPT are provided after the **Prompt:** and within the quotation marks. You should copy and paste these prompts into ChatGPT and ChatGPT should generate code very similar to the provided code in the code blocks. This is achieved by being very specific with the prompts, the more detail you leave out of a prompt, the more ChatGPT will have to infer, likely causing the code to deviate more from the provided code.\n",
        "\n",
        "**ChatGPT Conversation:** https://chatgpt.com/share/b25a1933-5ad9-476a-96f9-b8f8a5d18c74\n",
        "\n",
        "Once we begin working with outside data sources, you will need to update file paths in ChatGPT's generated code to wherever the provided data resides on your machine, we may also want to modify the example usage of the functions depending on how ChatGPT presents it's generated code, but the functions themselves shouldn't need any modification.\n",
        "\n",
        "If you encounter an error running the ChatGPT generated code, try resending the prompt to ChatGPT by editing your message by clicking the pencil icon that pops up in ChatGPT when you hover over your message and simply hitting send again. I've tested the prompts used several times over and they have worked for me, but that's not a guarentee they will work 100% of the time. However, there is enough randomness in ChatGPT's responses that simply resending the same message can be enough to have it correct it's course. If after two times of re-running the same prompt still doesn't yield working code, copy and paste the error into ChatGPT and see if it can correct the code for the error.\n",
        "\n",
        "Start by pip installing the libaries below if you do not already have them installed."
      ],
      "metadata": {
        "id": "a8yZNSrzlqOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas geopandas rasterio -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w665kmaBdUYi",
        "outputId": "68cee8ef-2f42-40fe-be0b-af7dcd29b5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Basic Hydrological Calculations\n",
        "\n",
        "### 1.1 Rational Method Function\n",
        "\n",
        "The Rational Method is a simple technique for estimating peak discharge from small watersheds. Let's use AI to help us create a function for this calculation.\n",
        "\n",
        "When using AI for coding assistance, it's important to provide clear, specific prompts. Here's an example prompt we might use:\n",
        "\n",
        "**Prompt:** \"Write a Python function to calculate peak discharge using the Rational Method. The function should take runoff coefficient (C, unitless), rainfall intensity (i, inches per hour), and drainage area (A, acres) as inputs and return the peak discharge (Q, cfs).\"\n",
        "\n",
        "Now, let's see the function an AI might generate:"
      ],
      "metadata": {
        "id": "-6h4Vli52rO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DWTQWSelf1j",
        "outputId": "2af1bd60-ce6c-47ca-e7db-968627aa020e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peak Discharge: 18.75 cfs\n"
          ]
        }
      ],
      "source": [
        "def calculate_peak_discharge(C, i, A):\n",
        "    \"\"\"\n",
        "    Calculate the peak discharge using the Rational Method.\n",
        "\n",
        "    Parameters:\n",
        "    C (float): Runoff coefficient (unitless)\n",
        "    i (float): Rainfall intensity (inches per hour)\n",
        "    A (float): Drainage area (acres)\n",
        "\n",
        "    Returns:\n",
        "    float: Peak discharge (cfs)\n",
        "    \"\"\"\n",
        "    # Rational Method formula\n",
        "    Q = C * i * A\n",
        "\n",
        "    return Q\n",
        "\n",
        "# Example usage\n",
        "C = 0.75  # Runoff coefficient\n",
        "i = 2.5   # Rainfall intensity (inches/hour)\n",
        "A = 10    # Drainage area (acres)\n",
        "\n",
        "peak_discharge = calculate_peak_discharge(C, i, A)\n",
        "print(f\"Peak Discharge: {peak_discharge:.2f} cfs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** ChatGPT can not only write Python code, but execute the code as well using a tool called \"Code Interpreter\". Can you instruct ChatGPT to run the function on example data C = 0.60, i = 3.0 in/hr and A = 12 acres?"
      ],
      "metadata": {
        "id": "KFMI5UlummVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Using the Function in a Loop\n",
        "\n",
        "Now that we have our basic function, let's use it to calculate peak discharge for multiple subbasins. We'll use a pandas dataframe to store subbasin data.\n",
        "\n",
        "**Prompt:**\n",
        "\"Write a Python script that uses the rational method function you just created in a for loop to calculate peak discharge for multiple subbasins. Generate a pandas dataframe to store subbasin data including subbasin name, C (runoff coefficient), i (rainfall intensity in inches per hour), and A (drainage area in acres) values.\"\n",
        "\n",
        "Based on this prompt, here's an example of the code an AI might generate:"
      ],
      "metadata": {
        "id": "DEf3Na5vnAWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the function to calculate peak discharge\n",
        "def calculate_peak_discharge(C, i, A):\n",
        "    \"\"\"\n",
        "    Calculate the peak discharge using the Rational Method.\n",
        "\n",
        "    Parameters:\n",
        "    C (float): Runoff coefficient (unitless)\n",
        "    i (float): Rainfall intensity (inches per hour)\n",
        "    A (float): Drainage area (acres)\n",
        "\n",
        "    Returns:\n",
        "    float: Peak discharge (cfs)\n",
        "    \"\"\"\n",
        "    Q = C * i * A\n",
        "    return Q\n",
        "\n",
        "# Subbasin data (name, C, i, A)\n",
        "subbasin_data = [\n",
        "    {\"name\": \"Subbasin 1\", \"C\": 0.60, \"i\": 3.0, \"A\": 12},\n",
        "    {\"name\": \"Subbasin 2\", \"C\": 0.75, \"i\": 2.8, \"A\": 10},\n",
        "    {\"name\": \"Subbasin 3\", \"C\": 0.50, \"i\": 3.2, \"A\": 15},\n",
        "    {\"name\": \"Subbasin 4\", \"C\": 0.65, \"i\": 2.5, \"A\": 8},\n",
        "    {\"name\": \"Subbasin 5\", \"C\": 0.70, \"i\": 3.1, \"A\": 9}\n",
        "]\n",
        "\n",
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop through each subbasin and calculate the peak discharge\n",
        "for subbasin in subbasin_data:\n",
        "    name = subbasin[\"name\"]\n",
        "    C = subbasin[\"C\"]\n",
        "    i = subbasin[\"i\"]\n",
        "    A = subbasin[\"A\"]\n",
        "\n",
        "    # Calculate peak discharge\n",
        "    Q = calculate_peak_discharge(C, i, A)\n",
        "\n",
        "    # Store the result\n",
        "    results.append({\n",
        "        \"Subbasin Name\": name,\n",
        "        \"Runoff Coefficient (C)\": C,\n",
        "        \"Rainfall Intensity (i) (in/hr)\": i,\n",
        "        \"Drainage Area (A) (acres)\": A,\n",
        "        \"Peak Discharge (Q) (cfs)\": Q\n",
        "    })\n",
        "\n",
        "# Create a pandas dataframe from the results\n",
        "df_subbasins = pd.DataFrame(results)\n",
        "\n",
        "# Display the dataframe\n",
        "print(df_subbasins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJY5Oa5lnfKy",
        "outputId": "b848cf68-5994-4789-afaf-8999d75ea169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Subbasin Name  Runoff Coefficient (C)  Rainfall Intensity (i) (in/hr)  \\\n",
            "0    Subbasin 1                    0.60                             3.0   \n",
            "1    Subbasin 2                    0.75                             2.8   \n",
            "2    Subbasin 3                    0.50                             3.2   \n",
            "3    Subbasin 4                    0.65                             2.5   \n",
            "4    Subbasin 5                    0.70                             3.1   \n",
            "\n",
            "   Drainage Area (A) (acres)  Peak Discharge (Q) (cfs)  \n",
            "0                         12                     21.60  \n",
            "1                         10                     21.00  \n",
            "2                         15                     24.00  \n",
            "3                          8                     13.00  \n",
            "4                          9                     19.53  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates how we can efficiently calculate peak discharge for multiple subbasins using a loop.\n",
        "\n",
        "**Exercise:** Can you instruct ChatGPT to run the function on example data (if it didn't do so already) and create a bar chart that shows the discharge per unit area for each subbasin? In practice, understanding the discharge per unit area allows you to spot any outliers which may require further investigation."
      ],
      "metadata": {
        "id": "PKNICatkbvfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Incorporating GIS Data for Calculating Subbasin Parameters\n",
        "When actually performing hydrologic analyses, we will typically be working with GIS data. We will have ChatGPT help us write code that will take in shapefiles and rasters and perform geospatial operations utilizing Geopandas and Rasterio to determine hydrologic parameters.\n",
        "\n",
        "### 2.1 Subbasin Areas\n",
        "We'll start by simply having ChatGPT write us code that will determine the easiest parameter, the subbasin area based on the provided Subbasins.shp shapefile.\n",
        "\n",
        "**Prompt:** \"Write a function that takes a polygon shapefile as an input, calculates the area of each polygon in acres. The function should return a pandas dataframe containing the original shapefile attributes and the calculated area. Assume the shapefile coordinates are in US Customary units.\""
      ],
      "metadata": {
        "id": "t14ItxwzGGSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "def calculate_polygon_area_in_acres(shapefile_path):\n",
        "    \"\"\"\n",
        "    Calculate the area of each polygon in a shapefile in acres.\n",
        "\n",
        "    Parameters:\n",
        "    shapefile_path (str): The path to the polygon shapefile.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A pandas DataFrame containing the original shapefile attributes and the calculated area in acres.\n",
        "    \"\"\"\n",
        "    # Read the shapefile using geopandas\n",
        "    gdf = gpd.read_file(shapefile_path)\n",
        "\n",
        "    # Ensure the geometries are in projected coordinates (feet) if necessary\n",
        "    # If the CRS is not already in feet (assumed), we may need to reproject (EPSG: 2249 for feet-based CRS, for example)\n",
        "\n",
        "    # Calculate the area in square feet and convert to acres\n",
        "    gdf['Area (acres)'] = gdf.geometry.area / 43560  # Convert square feet to acres\n",
        "\n",
        "    # Convert the geopandas GeoDataFrame to a pandas DataFrame\n",
        "    df = pd.DataFrame(gdf.drop(columns='geometry'))\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "shapefile_path = \"/content/Subbasins.shp\"\n",
        "result_df = calculate_polygon_area_in_acres(shapefile_path)\n",
        "print(result_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40hirkshctX3",
        "outputId": "f3dde034-6382-42eb-e1e5-31edea03bede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name       area  Area (acres)\n",
            "0  SB010  59.410480     59.410480\n",
            "1  SB020  64.968865     64.968865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** Can you have ChatGPT explain how a geopandas dataframe is different than a pandas dataframe?"
      ],
      "metadata": {
        "id": "FSmM1LOmtIsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Integrating GIS Data for Area-Weighted Average Runoff Coefficients\n",
        "\n",
        "The runoff coefficient (C) is determined based on the types of land uses within the subbasin. There is a \"Land_Use.shp\" shapefile provided with the land uses delineated and C values assigned to each land use in the attribute table of the shapefile in the field named \"C_Value\". The runoff coefficient for each subbasin is determined by calculating the area-weighted average C value within each subbasin. We will have ChatGPT write us a function that will perform these area-weighted C value calculations based on the intersection of the land use and subbasins data.\n",
        "\n",
        "To test the function that ChatGPT creates you will need to pass in the function arguments for the subbasin shapefile file path, land use shapefile file path, the attribute table field for the C values (\"C_Value\" in this case) and the attribute table field name for the subbasin IDs (\"name\" in this caes).\n",
        "\n",
        "**Prompt:** \"Write me a function that will take two polygon shapefiles as input, one representing subbasins and the other representing land use, as well as a attribute table field name for where the land use runoff coefficient (C) is stored and an attribute table field name where the subbasin IDs are stored. The function should calculate the area weighted average runoff coefficient (C) for each subbasin in the subbasins shapefile. The function should return a pandas dataframe containing the original subbasin shapefile attributes and the calculated area-weighted average runoff coefficients. Assume the coordinates for both shapefiles are in US customary units.\""
      ],
      "metadata": {
        "id": "77M2Hp1Ck01r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_area_weighted_runoff(subbasins_shapefile, landuse_shapefile, landuse_C_field, subbasin_id_field):\n",
        "    \"\"\"\n",
        "    Calculate the area-weighted average runoff coefficient (C) for each subbasin.\n",
        "\n",
        "    Parameters:\n",
        "    subbasins_shapefile (str): The path to the subbasin polygon shapefile.\n",
        "    landuse_shapefile (str): The path to the land use polygon shapefile.\n",
        "    landuse_C_field (str): The field name where the land use runoff coefficient (C) is stored in the land use shapefile.\n",
        "    subbasin_id_field (str): The field name where the subbasin IDs are stored in the subbasin shapefile.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A pandas DataFrame containing the original subbasin attributes and the calculated area-weighted average runoff coefficients (C).\n",
        "    \"\"\"\n",
        "    # Step 1: Load the subbasins and land use shapefiles using GeoPandas\n",
        "    subbasins_gdf = gpd.read_file(subbasins_shapefile)\n",
        "    landuse_gdf = gpd.read_file(landuse_shapefile)\n",
        "\n",
        "    # Step 2: Overlay (spatial join) the land use polygons with the subbasin polygons\n",
        "    # This performs an intersection to calculate the overlapping areas of land use in each subbasin\n",
        "    overlay_gdf = gpd.overlay(landuse_gdf, subbasins_gdf, how='intersection')\n",
        "\n",
        "    # Step 3: Calculate the area of each intersected polygon (in square feet)\n",
        "    overlay_gdf['Area_sqft'] = overlay_gdf.geometry.area\n",
        "\n",
        "    # Step 4: Calculate the weighted contribution of each land use polygon to the total subbasin\n",
        "    # Multiply the land use area by its runoff coefficient (C)\n",
        "    overlay_gdf['Weighted_C'] = overlay_gdf[landuse_C_field] * overlay_gdf['Area_sqft']\n",
        "\n",
        "    # Step 5: Group by subbasin to calculate the area-weighted average runoff coefficient for each subbasin\n",
        "    grouped = overlay_gdf.groupby(subbasin_id_field).agg(\n",
        "        total_area=('Area_sqft', 'sum'),\n",
        "        total_weighted_C=('Weighted_C', 'sum')\n",
        "    )\n",
        "\n",
        "    # Calculate the area-weighted average runoff coefficient for each subbasin\n",
        "    grouped['Area_Weighted_C'] = grouped['total_weighted_C'] / grouped['total_area']\n",
        "\n",
        "    # Step 6: Merge the calculated values back with the original subbasin attributes\n",
        "    result_gdf = subbasins_gdf.merge(grouped[['Area_Weighted_C']], left_on=subbasin_id_field, right_index=True)\n",
        "\n",
        "    # Step 7: Convert the result to a pandas DataFrame (excluding the geometry)\n",
        "    result_df = pd.DataFrame(result_gdf.drop(columns='geometry'))\n",
        "\n",
        "    return result_df\n",
        "\n",
        "# Example usage:\n",
        "subbasins_shapefile = \"/content/Subbasins.shp\"\n",
        "landuse_shapefile = \"/content/Land_Use.shp\"\n",
        "landuse_C_field = \"C_Value\"\n",
        "subbasin_id_field = \"name\"\n",
        "result_df = calculate_area_weighted_runoff(subbasins_shapefile, landuse_shapefile, landuse_C_field, subbasin_id_field)\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAYVPsoRm1T4",
        "outputId": "ee8a33c2-7e3c-48c8-fba2-2e257d4f4d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name       area  Area_Weighted_C\n",
            "0  SB010  59.410480         0.539037\n",
            "1  SB020  64.968865         0.621546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Integrating GIS Data for Time of Concentration\n",
        "\n",
        "Now, let's integrate GIS data to calculate the time of concentration using the Kirpich formula. This time of concentration using the Kirpich method depends on the length and slope of the longest flow path within a subbasin.  We'll use the provided flow path line shapefile and the raster digital elevation model (DEM) and have ChatGPT write functions to extract elevations from the DEM, calculate the length and slope of each flow path, then finally calculate the time of concentration for each subbasin. The function will require as inputs the flow path shapefile, DEM, and the attribute table field name that contains the ID for each flow path (just the string \"name\" in our case).\n",
        "\n",
        "In the prompt you'll notice that I refer to the flow paths shapefile as a \"MultiLineString\". This helps ChatGPT understand the type of data that the function will be working with. A MultiLineString shapefile is a specific type of shapefile geometry that represents multiple lines (or polylines) as a single feature. These individual lines, known as \"LineStrings,\" are grouped together to form a single multi-part feature. This differs from a standard Line shapefile, which typically represents each line as a separate feature."
      ],
      "metadata": {
        "id": "jlLZdt8jepfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt** \"Write a function that takes in a MultiLineString shapefile representing the subbasin flow paths, a raster DEM and the flow path ID attribute table field name as input. Extract the DEM elevations at the start and end of each feature in the MultiLineString shapefile, calculate the length of each feature (in feet), then use this data to calculate the slope (feet/feet) of each feature. Use the determined length and slope to calculate the time of concentration each feature using the Kirpich method. The Kirpich time of concentration formula is shown below:\n",
        "\n",
        "Tc = 0.0078(L^0.77)(S^-0.385)\n",
        "\n",
        "where: Tc = time of concentration (minutes) L = length (feet) S = slope (feet/feet)\n",
        "\n",
        "The function should return a dataframe with all the original shapefile attributes and the calculated lengths, start and end elevations, slopes and time of concentration (minutes). Assume the coordinates of the line shapefile are in US Customary units.\""
      ],
      "metadata": {
        "id": "V4t6eUmZe0mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "from shapely.geometry import LineString\n",
        "import numpy as np\n",
        "\n",
        "def calculate_time_of_concentration(flowpaths_shapefile, dem_raster, flowpath_id_field):\n",
        "    \"\"\"\n",
        "    Calculate the length, start and end elevations, slope, and time of concentration (Tc) for each flow path\n",
        "    in a MultiLineString shapefile using the Kirpich method.\n",
        "\n",
        "    Parameters:\n",
        "    flowpaths_shapefile (str): Path to the MultiLineString shapefile representing the subbasin flow paths.\n",
        "    dem_raster (str): Path to the raster DEM file.\n",
        "    flowpath_id_field (str): The field name where the flow path IDs are stored.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A pandas DataFrame containing the original shapefile attributes and the calculated lengths,\n",
        "                  start and end elevations, slopes, and time of concentration (Tc).\n",
        "    \"\"\"\n",
        "    # Step 1: Load the flowpaths shapefile using GeoPandas\n",
        "    flowpaths_gdf = gpd.read_file(flowpaths_shapefile)\n",
        "\n",
        "    # Step 2: Open the DEM raster using Rasterio\n",
        "    with rasterio.open(dem_raster) as dem:\n",
        "        # Step 3: Initialize an empty list to store results\n",
        "        results = []\n",
        "\n",
        "        # Step 4: Iterate over each flowpath in the shapefile\n",
        "        for idx, row in flowpaths_gdf.iterrows():\n",
        "            flowpath = row.geometry\n",
        "\n",
        "            # Check if the geometry is a LineString or MultiLineString and extract the coordinates\n",
        "            if isinstance(flowpath, LineString):\n",
        "                coords = list(flowpath.coords)\n",
        "            else:\n",
        "                # If MultiLineString, use the first component\n",
        "                coords = list(flowpath[0].coords)\n",
        "\n",
        "            # Extract the start and end coordinates\n",
        "            start_coords = coords[0]\n",
        "            end_coords = coords[-1]\n",
        "\n",
        "            # Step 5: Get the elevation at the start and end points from the DEM\n",
        "            start_elev = list(dem.sample([start_coords]))[0][0]\n",
        "            end_elev = list(dem.sample([end_coords]))[0][0]\n",
        "\n",
        "            # Step 6: Calculate the length of the flow path (in feet)\n",
        "            length = flowpath.length\n",
        "\n",
        "            # Step 7: Calculate the slope (S) in feet/feet\n",
        "            slope = (start_elev - end_elev) / length\n",
        "\n",
        "            # Step 8: Calculate the time of concentration (Tc) using the Kirpich method\n",
        "            if slope > 0:  # Ensure the slope is positive\n",
        "                Tc = 0.0078 * (length ** 0.77) * (slope ** -0.385)\n",
        "            else:\n",
        "                Tc = np.nan  # Handle case where slope is negative or zero (invalid case for the Kirpich formula)\n",
        "\n",
        "            # Step 9: Store the results\n",
        "            results.append({\n",
        "                flowpath_id_field: row[flowpath_id_field],\n",
        "                'Length (ft)': length,\n",
        "                'Start Elevation (ft)': start_elev,\n",
        "                'End Elevation (ft)': end_elev,\n",
        "                'Slope (ft/ft)': slope,\n",
        "                'Time of Concentration (min)': Tc\n",
        "            })\n",
        "\n",
        "    # Step 10: Convert the results to a pandas DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Step 11: Merge the original flowpaths shapefile attributes with the calculated results\n",
        "    final_df = pd.merge(flowpaths_gdf.drop(columns='geometry'), results_df, on=flowpath_id_field)\n",
        "\n",
        "    return final_df\n",
        "\n",
        "# Example usage:\n",
        "# flowpaths_shapefile = \"path_to_flowpaths.shp\"\n",
        "# dem_raster = \"path_to_dem.tif\"\n",
        "# flowpath_id_field = \"flowpath_id\"\n",
        "# result_df = calculate_time_of_concentration(flowpaths_shapefile, dem_raster, flowpath_id_field)\n",
        "# print(result_df)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "flow_paths_shapefile = '/content/Flow_Paths.shp'\n",
        "dem_raster = '/content/DEM_NAD83.tif'\n",
        "flow_path_id_field = \"name\"  # Example flow path ID field name\n",
        "\n",
        "result_df = calculate_time_of_concentration(flow_paths_shapefile, dem_raster, flow_path_id_field)\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vALmSBMIf3_J",
        "outputId": "03b77cde-d172-44a9-9d5d-3ea6f6d854c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name  Length (ft)  Start Elevation (ft)  End Elevation (ft)  \\\n",
            "0  SB010  3023.137260           1536.305908         1471.551514   \n",
            "1  SB020  2798.769445           1542.776123         1475.628418   \n",
            "\n",
            "   Slope (ft/ft)  Time of Concentration (min)  \n",
            "0       0.021420                    16.393994  \n",
            "1       0.023992                    14.788858  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** Can you get ChatGPT to explain the code that extracts the raster values at the line start and end points step by step?"
      ],
      "metadata": {
        "id": "QOOqo7alhGyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Incorporating NOAA Atlas 14 Data\n",
        "\n",
        "In real-world scenarios, we often need to work with rainfall data from sources like NOAA Atlas 14. The time of concentration (Tc) of a watershed is crucial for determining the appropriate rainfall intensity to use in our calculations. NOAA Atlas 14 provides rainfall depths for various durations, but we typically need to interpolate to find the intensity for our specific Tc. Let's create a function to interpolate rainfall intensity for a given time of concentration using NOAA Atlas 14 data."
      ],
      "metadata": {
        "id": "HzV2MaV9cF7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt** \"Write a Python function that interpolates rainfall intensity from NOAA Atlas 14 data for a given time of concentration. The function should:\n",
        "\n",
        "1. Take a single parameter 'tc' (time of concentration in minutes).\n",
        "2. Use a predefined csv file containing the NOAA Atlas 14 data where the csv is formatted as first column is durations in minutes and second column is rainfall depths in inches.\n",
        "3. Return the interpolated rainfall depth in inches and rainfall intensity in inches/hour\""
      ],
      "metadata": {
        "id": "DiCU8DSlcv2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.interpolate import interp1d\n",
        "\n",
        "def interpolate_rainfall_intensity(tc, csv_file):\n",
        "    \"\"\"\n",
        "    Interpolates the rainfall depth and calculates rainfall intensity for a given time of concentration (tc)\n",
        "    using NOAA Atlas 14 data from a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "    tc (float): Time of concentration in minutes.\n",
        "    csv_file (str): Path to the CSV file containing NOAA Atlas 14 data with durations (minutes) and rainfall depths (inches).\n",
        "\n",
        "    Returns:\n",
        "    tuple: Interpolated rainfall depth in inches and rainfall intensity in inches per hour.\n",
        "    \"\"\"\n",
        "    # Step 1: Load NOAA Atlas 14 data from the CSV file\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Ensure that the CSV has the correct columns: first column as durations (minutes), second as rainfall depths (inches)\n",
        "    durations = df.iloc[:, 0].values  # Durations in minutes\n",
        "    rainfall_depths = df.iloc[:, 1].values  # Rainfall depths in inches\n",
        "\n",
        "    # Step 2: Use interpolation to estimate the rainfall depth for the given time of concentration (tc)\n",
        "    # We use 'linear' interpolation, which works well for evenly spaced data like this.\n",
        "    interpolate_function = interp1d(durations, rainfall_depths, kind='linear', fill_value='extrapolate')\n",
        "\n",
        "    # Interpolate the rainfall depth for the given tc (time of concentration)\n",
        "    interpolated_depth = interpolate_function(tc)\n",
        "\n",
        "    # Step 3: Calculate the rainfall intensity (inches/hour)\n",
        "    # Rainfall intensity is calculated as depth (inches) divided by duration (hours)\n",
        "    rainfall_intensity = interpolated_depth / (tc / 60)  # Convert tc from minutes to hours\n",
        "\n",
        "    return interpolated_depth, rainfall_intensity\n",
        "\n",
        "# Example usage:\n",
        "csv_file = '/content/NOAA_Rainfall_Data.csv'  # Replace with the actual path to your CSV file\n",
        "tc = 45  # Example time of concentration in minutes\n",
        "depth, intensity = interpolate_rainfall_intensity(tc, csv_file)\n",
        "print(f\"Interpolated Rainfall Depth: {depth:.3f} inches\")\n",
        "print(f\"Rainfall Intensity: {intensity:.3f} inches/hour\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcG0cgH7damL",
        "outputId": "6ecffcb0-1c21-45aa-e4e4-f530b58510fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interpolated Rainfall Depth: 2.015 inches\n",
            "Rainfall Intensity: 2.687 inches/hour\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function demonstrates linear interpolation, a common technique in hydrology for estimating values between known data points. The NOAA Atlas 14 data provides rainfall depths for specific durations, and we often need to estimate intensities for times of concentration that fall between these durations.\n",
        "\n",
        "**Exercise:** Can you upload the provided \"NOAA_Rainfall_Data.csv\" to ChatGPT and instruct ChatGPT to create a plot of rainfall depth versus duration? Can you instruct ChatGPT to modify the plot by adding axes labels, grid lines, title or changing the line color?\n"
      ],
      "metadata": {
        "id": "bL07cg34JwN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Putting It All Together\n",
        "Now lets have ChatGPT create one final function that utilizes all of the functions that we've created so far that take in all the shapefile, raster and csv data and return a dataframe with all the calculated subbasin parameters and peak discharges.\n",
        "\n",
        "**Prompt:** \"Create a Python function that utilizes all the functions we've developed in this conversation to:\n",
        "\n",
        "Calculate subbasin area from the subbasins shapefile\n",
        "Calculate the area-weighted average runoff coefficients for each subbasin\n",
        "Calculate the time of concentration for each subbasin\n",
        "Calculate the rainfall intensity for each subbasin\n",
        "Calculate the peak discharge for each subbasin\n",
        "The function should return a dataframe with all the calculated subbasin parameters including the subbasin ID, area, area-weighted runoff coefficient, time of concentration, rainfall intensity and peak discharge.\n",
        "\n",
        "Do not rewrite the functions, simply just use the functions that you've already created.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "9KM2zWD1cQPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_subbasin_parameters(subbasins_shapefile, landuse_shapefile, flowpaths_shapefile, dem_raster,\n",
        "                                  flowpath_id_field, landuse_C_field, subbasin_id_field, csv_file_noaa):\n",
        "    \"\"\"\n",
        "    Calculate subbasin parameters including area, area-weighted runoff coefficient, time of concentration,\n",
        "    rainfall intensity, and peak discharge for each subbasin.\n",
        "\n",
        "    Parameters:\n",
        "    subbasins_shapefile (str): Path to the subbasin polygon shapefile.\n",
        "    landuse_shapefile (str): Path to the land use polygon shapefile.\n",
        "    flowpaths_shapefile (str): Path to the flow paths (MultiLineString) shapefile.\n",
        "    dem_raster (str): Path to the DEM raster file.\n",
        "    flowpath_id_field (str): The field name where flow path IDs are stored in the flowpath shapefile.\n",
        "    landuse_C_field (str): The field name where the land use runoff coefficient (C) is stored in the land use shapefile.\n",
        "    subbasin_id_field (str): The field name where subbasin IDs are stored in the subbasin shapefile.\n",
        "    csv_file_noaa (str): Path to the CSV file containing NOAA Atlas 14 data (durations and rainfall depths).\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A pandas DataFrame containing the subbasin parameters including area, area-weighted C,\n",
        "                  time of concentration, rainfall intensity, and peak discharge.\n",
        "    \"\"\"\n",
        "    # 1. Calculate subbasin area\n",
        "    subbasin_area_df = calculate_polygon_area_in_acres(subbasins_shapefile)\n",
        "\n",
        "    # 2. Calculate the area-weighted average runoff coefficients for each subbasin\n",
        "    runoff_coefficient_df = calculate_area_weighted_runoff(subbasins_shapefile, landuse_shapefile,\n",
        "                                                           landuse_C_field, subbasin_id_field)\n",
        "\n",
        "    # Merge the area and area-weighted C dataframes on the subbasin ID\n",
        "    subbasin_df = pd.merge(subbasin_area_df, runoff_coefficient_df, on=subbasin_id_field)\n",
        "\n",
        "    # 3. Calculate the time of concentration for each subbasin\n",
        "    time_of_concentration_df = calculate_time_of_concentration(flowpaths_shapefile, dem_raster, flowpath_id_field)\n",
        "\n",
        "    # Merge with the existing dataframe\n",
        "    subbasin_df = pd.merge(subbasin_df, time_of_concentration_df, on=subbasin_id_field)\n",
        "\n",
        "    # 4. Calculate the rainfall intensity for each subbasin using time of concentration\n",
        "    subbasin_df['Rainfall Depth (inches)'] = subbasin_df['Time of Concentration (min)'].apply(\n",
        "        lambda tc: interpolate_rainfall_intensity(tc, csv_file_noaa)[0])\n",
        "\n",
        "    subbasin_df['Rainfall Intensity (in/hr)'] = subbasin_df['Time of Concentration (min)'].apply(\n",
        "        lambda tc: interpolate_rainfall_intensity(tc, csv_file_noaa)[1])\n",
        "\n",
        "    # 5. Calculate the peak discharge for each subbasin using the Rational Method\n",
        "    subbasin_df['Peak Discharge (cfs)'] = subbasin_df.apply(\n",
        "        lambda row: calculate_peak_discharge(row['Area_Weighted_C'], row['Rainfall Intensity (in/hr)'], row['Area (acres)']),\n",
        "        axis=1)\n",
        "\n",
        "    # Return the final dataframe with all calculated subbasin parameters\n",
        "    return subbasin_df\n",
        "\n",
        "# Define the file paths and field names as variables\n",
        "subbasins_shapefile = \"/content/Subbasins.shp\"  # Path to your subbasins shapefile\n",
        "landuse_shapefile = \"/content/Land_Use.shp\"  # Path to your land use shapefile\n",
        "flowpaths_shapefile = \"/content/Flow_Paths.shp\"  # Path to your flow paths shapefile\n",
        "dem_raster = \"/content/DEM_NAD83.tif\"  # Path to your DEM raster file\n",
        "flowpath_id_field = \"name\"  # Field name in flowpaths shapefile for the flow path IDs\n",
        "landuse_C_field = \"C_Value\"  # Field name in land use shapefile for the runoff coefficient\n",
        "subbasin_id_field = \"name\"  # Field name in subbasins shapefile for the subbasin IDs\n",
        "csv_file_noaa = \"/content/NOAA_Rainfall_Data.csv\"  # Path to your NOAA Atlas 14 CSV file\n",
        "\n",
        "# Call the function with the specified variables\n",
        "result_df = calculate_subbasin_parameters(subbasins_shapefile, landuse_shapefile, flowpaths_shapefile, dem_raster,\n",
        "                                          flowpath_id_field, landuse_C_field, subbasin_id_field, csv_file_noaa)\n",
        "\n",
        "# Print or display the resulting DataFrame with subbasin parameters\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEhbXhRwcUT4",
        "outputId": "d12dbf0e-b5b3-4c0d-ea9f-990a3037aa8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name     area_x  Area (acres)     area_y  Area_Weighted_C  Length (ft)  \\\n",
            "0  SB010  59.410480     59.410480  59.410480         0.539037  3023.137260   \n",
            "1  SB020  64.968865     64.968865  64.968865         0.621546  2798.769445   \n",
            "\n",
            "   Start Elevation (ft)  End Elevation (ft)  Slope (ft/ft)  \\\n",
            "0           1536.305908         1471.551514       0.021420   \n",
            "1           1542.776123         1475.628418       0.023992   \n",
            "\n",
            "   Time of Concentration (min)  Rainfall Depth (inches)  \\\n",
            "0                    16.393994                 1.382749   \n",
            "1                    14.788858                 1.329021   \n",
            "\n",
            "   Rainfall Intensity (in/hr)  Peak Discharge (cfs)  \n",
            "0                    5.060692            162.065918  \n",
            "1                    5.391981            217.734421  \n"
          ]
        }
      ]
    }
  ]
}