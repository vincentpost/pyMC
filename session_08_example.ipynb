{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Example data analysis from participants\n",
    "\n",
    "*Name, Surname, 26th of September, 2024*\n",
    "\n",
    "In this notebook the stream Gauge data is analysed, with the main goal of identifying the ten highest flow for the period with records.\n",
    "\n",
    "Files: `Gauge 1.csv`, `Gauge 2.csv`\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Clean up the data, and select data using a quality code.\n",
    "- Extract daily and annual data from the 6-minute data. Daily for following analysis and annual for Flood Frequency Analysis.\n",
    "- Identify the top 10 high flow values for each gauge in the daily data, including corresponding dates and levels.\n",
    "- For the dates of the top 10 high flows in Gauge 1, find the corresponding flow and level in the second dataset \n",
    "- Tabulate these results for the report.\n",
    "\n",
    "### 0. Load python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    os.path.join(folder, \"Gauge 1.csv\"),\n",
    "    skiprows=127,\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    dayfirst=True,\n",
    "    usecols=[0, 2, 3],\n",
    "    names=[\"Date\", \"Quality\", \"Discharge\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Select data using one of the quality codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df[df.loc[:, \"Quality\"] == 1]\n",
    "df_selected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Resample to daily and annual discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_daily = df_selected.loc[:, \"Discharge\"].resample(\"D\").sum()\n",
    "q_annual = df_selected.loc[:, \"Discharge\"].resample(\"D\").sum().resample(\"YE\").max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot the discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_daily.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Select top 10 high flows and dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = q_daily.sort_values(ascending=False).head(10)\n",
    "top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. For the dates of the top 10 high flows in Gauge 1, find the corresponding flow and level in the second dataset \n",
    "\n",
    "#### 6a. Load the data from gauge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge2 = pd.read_csv(\n",
    "    os.path.join(folder, \"Gauge 2.csv\"),\n",
    "    skiprows=160,\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    dayfirst=True,\n",
    "    usecols=[0, 2, 3],\n",
    "    names=[\"Date\", \"Quality\", \"Discharge\"],\n",
    ")\n",
    "\n",
    "gauge2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: write a one-line script to select and resample\n",
    "\n",
    "Write a one-line script to only select the data with a quality label \"1\" and resample the selected data to daily sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and resample\n",
    "q2_daily = # Write your code here\n",
    "q2_daily\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6b. Plot the data\n",
    "\n",
    "To see that there is little overlap in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_daily.plot()\n",
    "q2_daily.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6c. Find values of gauge2 during the gauge1 top 10 flood events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_daily.loc[top10.index.round(\"D\")]  # Select the top 10 days from gauge 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only for the dates where there is data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idx = [idx for idx in top10.index if idx in q2_daily.index]\n",
    "\n",
    "top10_q2 = q2_daily.loc[good_idx]\n",
    "top10_q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to report the top 10 events\n",
    "\n",
    "top10_df = pd.DataFrame({\n",
    "    \"Gauge 1\": top10,\n",
    "    \"Gauge 2\": top10_q2,\n",
    "})\n",
    "\n",
    "\n",
    "# Export to excel\n",
    "top10_df.to_excel(\"top10.xlsx\")\n",
    "\n",
    "top10_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try some GitHub co-pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a flood frequency analysis using the Gumbel distribution on the anual maxima\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopandas_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
